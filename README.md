# ğŸ› Citation

If you find our work helpful for your research, please cite:

```bib
@inproceedings{zheng2024smaformer,
  title={Smaformer: Synergistic multi-attention transformer for medical image segmentation},
  author={Zheng, Fuchen and Chen, Xuhang and Liu, Weihuang and Li, Haolun and Lei, Yingtie and He, Jiahui and Pun, Chi-Man and Zhou, Shoujun},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
  pages={4048--4053},
  year={2024},
  organization={IEEE}
}

@article{zheng2025hbformer,
  title={HBFormer: A Hybrid-Bridge Transformer for Microtumor and Miniature Organ Segmentation},
  author={Zheng, Fuchen and Chen, Xinyi and Li, Weixuan and Li, Quanjun and Zhou, Junhua and Guo, Xiaojiao and Chen, Xuhang and Pun, Chi-Man and Zhou, Shoujun},
  journal={arXiv preprint arXiv:2512.03597},
  year={2025}
}

```
# ğŸ“‹SMAFormer

SMAFormer: Synergistic Multi-Attention Transformer for Medical Image Segmentation
[Vedio introduction](https://www.bilibili.com/video/BV1FLDsYqExZ/)

[Fuchen Zheng](https://lzeeorno.github.io/),  [Xuhang Chen](https://cxh.netlify.app/), Weihuang Liu, Haolun Li, Yingtie Lei, Jiahui He, [Chi-Man Pun](https://www.cis.um.edu.mo/~cmpun/) ğŸ“®and [Shoujun Zhou](https://people.ucas.edu.cn/~sjzhou?language=en) ğŸ“®( ğŸ“® Corresponding authors)

**University of Macau, SIAT CAS, Huizhou University, University of Nottingham Ningbo China**

2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM 2024)

---

## 1. æ¦‚è¿°

SMAFormer V2.3 æ˜¯åŸºäº Swin Transformer çš„åŒ»å­¦å›¾åƒåˆ†å‰²æ¶æ„ï¼Œå…¶ä¸­BIBM2024å¹´æœ€åˆç‰ˆæœ¬SMAFormeråŸºäºViTæ¶æ„ä½¿ç”¨äº†å¤§é‡å‚æ•°ï¼ˆ138Mï¼‰æ‰èƒ½å†Synapseæ•°æ®é›†è¾¾åˆ°86%çš„Diceã€‚å› æ­¤æˆ‘ä»¬å‚è€ƒBIBM2025HBFormerçš„è®¾è®¡ï¼Œåˆ‡æ¢æˆSwin Transformerçš„Backboneï¼Œåœ¨ä½¿ç”¨ä»…ä»…40Mçš„å‚æ•°é‡è¾¾åˆ°äº†89%çš„Diceã€‚SMAFomerV2.3é‡‡ç”¨åˆ›æ–°çš„**é•œåƒEncoder-Decoderè®¾è®¡**ï¼Œå®ç°äº†**åŒå‘é¢„è®­ç»ƒæƒé‡åŠ è½½**ã€‚è¯¥ç‰ˆæœ¬é€šè¿‡è®©Decoderå®Œå…¨é•œåƒEncoderçš„ç»“æ„ï¼Œå°†é¢„è®­ç»ƒæƒé‡è¦†ç›–ç‡ä»ä¼ ç»Ÿçš„65%å¤§å¹…æå‡è‡³**94.84%**ï¼Œä¸ºåŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡æä¾›äº†æ›´å¼ºçš„åˆå§‹åŒ–åŸºç¡€ã€‚

### æ ¸å¿ƒè®¾è®¡ç†å¿µ

V2.3ç‰ˆæœ¬éµå¾ª"**æœ€å¤§åŒ–é¢„è®­ç»ƒæƒé‡åˆ©ç”¨**"çš„è®¾è®¡å“²å­¦ï¼š
- ä¸å…¶è®¾è®¡å¤æ‚çš„Decoderæ¨¡å—ï¼ˆå¦‚V2.2çš„ASPPã€CAFFç­‰ï¼‰ï¼Œä¸å¦‚è®©Decoderé•œåƒEncoderç»“æ„
- Encoderå¯åŠ è½½Swin Tinyé¢„è®­ç»ƒæƒé‡ï¼ˆ100%è¦†ç›–ï¼‰
- Decoderé€šè¿‡åå‘æ˜ å°„ä¹Ÿå¯åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆ85.87%è¦†ç›–ï¼‰
- æ€»é¢„è®­ç»ƒè¦†ç›–ç‡è¾¾åˆ°**94.84%**ï¼Œè¿œè¶…ä¼ ç»ŸU-Netæ¶æ„ï¼ˆä»…Encoderæœ‰é¢„è®­ç»ƒï¼‰

## 2.ğŸŒ³ ç‰ˆæœ¬æ¼”è¿›æ ‘

```
                           SMAFormer
                               â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                                       â”‚
    [Branch: ViT-Base]                    [Branch: Swin-Tiny]
           â”‚                                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚  SMAFormer  â”‚                        â”‚ SMAFormerV2 â”‚
    â”‚  (ViT-Base) â”‚                        â”‚ (Swin-Tiny) â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                       â”‚
    v1.1 åŸå§‹ç‰ˆæœ¬                           v2.1 åŸå§‹ç‰ˆæœ¬
    Dice: 74%                              Dice: 78%
           â”‚                                       â”‚
    v1.2 [2024-12-21]                      v2.2 [2025-12-21]
    â”œâ”€ Adapteré£æ ¼SMA                      â”œâ”€ æ”¹è¿›SMAæ¨¡å—
    â”œâ”€ æ­£å¼¦ä½™å¼¦ä½ç½®ç¼–ç                      â”œâ”€ DynamicMultiScaleASPP
    â”œâ”€ DPTå¤šå°ºåº¦ç‰¹å¾                       â”œâ”€ CrossAttentionèåˆ
    â””â”€ UNet Decoder                        â””â”€ BoundaryAwareHead
           â”‚                                       â”‚
           â–¼                                       â”‚
    Dice: 80%                                     â”‚
                                                   â”‚
                                           v2.2 å¤æ‚ç‰¹å¾ç‰ˆæœ¬
                                           (ASPP+CAFF+è¾¹ç•Œå¤´)
                                           Dice: 80%
                                                   â”‚
                                           v2.3 â˜… é•œåƒæ¶æ„ [æœ€æ–°]
                                           â”œâ”€ Decoderé•œåƒEncoder
                                           â”œâ”€ åŒå‘é¢„è®­ç»ƒæƒé‡åŠ è½½
                                           â”œâ”€ Encoder: 100%åŠ è½½
                                           â””â”€ Decoder: 86%åŠ è½½
                                                   â”‚
                                                   â–¼
                                           Dice: 89%
```

---


#### ğŸ†š ç‰ˆæœ¬å¯¹æ¯”

| ç‰¹æ€§ | V2.1 | V2.2 | V2.3 |
|------|------|------|------|
| Decoderç±»å‹ | ConvNext | Complex (ASPP+CAFF) | **Mirror Swin** |
| Decoderé¢„è®­ç»ƒ | âŒ æ—  | âŒ æ—  | **âœ… 86%** |
| æ€»é¢„è®­ç»ƒè¦†ç›–ç‡ | ~65% | ~65% | **95%** |
| å‚æ•°é‡ | ~42M | ~55M | **41.4M** |
| è®¾è®¡å¤æ‚åº¦ | ä½ | é«˜ | **ä½** |
| Dice (éªŒè¯) | 78% | 80% | 89% |



---

## 3. ğŸ“ˆ æ€§èƒ½å¯¹æ¯”è¡¨

| æ¨¡å‹ | Backbone | åˆ‡ç‰‡Dice | 3D Dice | HD95 | çŠ¶æ€ |
|------|----------|----------|---------|------|------|
| HBFormer | Swin-Tiny | 98.56% | **87.82%** | **6.92** | âœ… åŸºå‡† |
| SMAFormer v1.1 | ViT-Base | 83.36% | 70% | 35+ | âŒ å·²åºŸå¼ƒ |
| SMAFormer v1.2 | ViT-Base | 98.12% | 86% | - | âŒ å·²åºŸå¼ƒ |
| SMAFormerV2 v2.1| Swin-Tiny | 95.32 | 78.66% | 27.51 | âŒ å·²åºŸå¼ƒ |
| SMAFormerV2 v2.2 | Swin-Tiny | 98.39 | 78.24% | 24.47 | âš ï¸ å¤æ‚ç‰¹å¾ |
| SMAFormerV2 v2.3 | Swin-Tiny | 98.36 | 89.41% | 6.64 | ğŸŒŸ **é•œåƒæ¶æ„** |

---

## 4. ğŸ”¬ æ”¹è¿›æ–¹æ³•å‚è€ƒæ–‡çŒ®

### æ³¨æ„åŠ›æœºåˆ¶
- **CBAM** (ECCV 2018): Convolutional Block Attention Module
- **SE-Net** (CVPR 2018): Squeeze-and-Excitation Networks  
- **ECA-Net** (CVPR 2020): Efficient Channel Attention

### åŠ¨æ€ç½‘ç»œ
- **ODConv** (ICLR 2022): Omni-Dimensional Dynamic Convolution
- **CondConv** (NeurIPS 2019): Conditionally Parameterized Convolutions

### Transformeræ”¹è¿›
- **ViT-Adapter** (ICLR 2023): Vision Transformer Adapter
- **DPT** (ICCV 2021): Vision Transformers for Dense Prediction
- **Swin-UNet** (arXiv 2021): Swin Transformer for Medical Segmentation

### åˆ†å‰²æ–¹æ³•
- **SegNeXt** (NeurIPS 2022): Rethinking Convolutional Attention
- **ConvNeXt V2** (CVPR 2023): Co-designing and Scaling ConvNets
- **NAFNet** (ECCV 2022): Simple Baselines for Image Restoration

### åŒ»å­¦å½±åƒ
- **TransUNet** (arXiv 2021): Transformers for Medical Image Segmentation
- **Swin-UNet** (arXiv 2021): Swin Transformer for Medical Segmentation
- **HBFormer**: BIBM2025

---

## 5. æ€§èƒ½ç‰¹ç‚¹

### å‚æ•°é‡ä¸è®¡ç®—é‡
- **Total Parameters**: 41.43M


### è®­ç»ƒé…ç½®
- **Input Size**: 256Ã—256
- **Batch Size**: 40 (a6000)
- **Optimizer**: AdamW (lr=0.0001)
- **Loss Function**: CE + Dice
- **Data Augmentation**: Pseudo-HDR preprocessing



## 6. é¢„è®­ç»ƒæƒé‡

### ä¸‹è½½æƒé‡
é¢„è®­ç»ƒæƒé‡ä¸‹è½½åˆ°`pre_trained_weights/`ç›®å½•ï¼š
```
pre_trained_weights/swin_tiny_patch4_window7_224.pth
```




## 7. SMAFormerV2 å„ç‰ˆæœ¬å·®å¼‚

| ç‰¹æ€§ | V2.1 | V2.2 | V2.3 (å½“å‰) |
|------|------|------|-------------|
| **Encoder** | Swin-Tiny | Swin-Tiny | Swin-Tiny |
| **Decoder** | ConvNeXt | Complex (ASPP+CAFF+è¾¹ç•Œå¤´) | **Mirror Swin** |
| **Encoderé¢„è®­ç»ƒ** | âœ… 100% | âœ… 100% | âœ… **100%** |
| **Decoderé¢„è®­ç»ƒ** | âŒ 0% | âŒ 0% | âœ… **85.87%** |
| **æ€»é¢„è®­ç»ƒè¦†ç›–** | ~65% | ~65% | âœ… **94.84%** |
| **å‚æ•°é‡** | ~42M | ~55M | âœ… **41.4M** |
| **è®¾è®¡å¤æ‚åº¦** | ä½ | é«˜ | âœ… **ä½** |
| **Dice (Synapse)** | ~78% | ~80% | ~89.41% |

### å…³é”®ä¼˜åŠ¿

1. **é¢„è®­ç»ƒè¦†ç›–ç‡æœ€é«˜**: 94.84% vs ä¼ ç»ŸUNetæ¶æ„çš„50-60%
2. **å‚æ•°æ•ˆç‡**: 41.4Må‚æ•°ï¼Œç›¸æ¯”V2.2å‡å°‘25%
3. **è®¾è®¡ç®€æ´**: é¿å…è¿‡åº¦è®¾è®¡ï¼Œä¸“æ³¨äºé¢„è®­ç»ƒæƒé‡åˆ©ç”¨
4. **è®­ç»ƒç¨³å®š**: Decoderä¹Ÿæœ‰è‰¯å¥½åˆå§‹åŒ–ï¼Œæ”¶æ•›æ›´å¿«


----

## 8. è®­ç»ƒSMAFormer (å®Œæ•´ç‰ˆ)

```
python train_synapse.py --max_epochs 300 --batch_size 40 --model SMAFormerV2 --config configs/config_setting_synapse.py
```


## 9. è¯„ä¼°

```bash
# æµ‹è¯•æ¨¡å‹
python test_synapse.py --model_path checkpoints/best.pth
```


### æŸ¥çœ‹æƒé‡åŠ è½½æƒ…å†µ

æ¨¡å‹åˆå§‹åŒ–æ—¶ä¼šè‡ªåŠ¨æ‰“å°é¢„è®­ç»ƒæƒé‡åŠ è½½æŠ¥å‘Šï¼š

```
================================================================================
SMAFormerV2 V2.3 - åŒå‘é¢„è®­ç»ƒæƒé‡åŠ è½½æŠ¥å‘Š
================================================================================

ğŸ“¦ [1/2] åŠ è½½ Encoder é¢„è®­ç»ƒæƒé‡...
   â”œâ”€ Encoderå‚æ•°æ€»é‡: 27,519,354
   â”œâ”€ æˆåŠŸåŠ è½½å‚æ•°é‡: 27,519,354
   â””â”€ åŠ è½½æˆåŠŸç‡: 100.00%

ğŸ“¦ [2/2] åŠ è½½ Decoder é¢„è®­ç»ƒæƒé‡ (åå‘æ˜ å°„)...
   â”œâ”€ Decoderå‚æ•°æ€»é‡: 13,712,778
   â”œâ”€ æˆåŠŸåŠ è½½å‚æ•°é‡: 11,775,402
   â””â”€ åŠ è½½æˆåŠŸç‡: 85.87%

================================================================================
ğŸ“Š é¢„è®­ç»ƒæƒé‡åŠ è½½æ€»ç»“
================================================================================
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Encoder åŠ è½½ç‡: 100.00%  (27,519,354/27,519,354)   â”‚
   â”‚  Decoder åŠ è½½ç‡:  85.87%  (11,775,402/13,712,778)   â”‚
   â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
   â”‚  æ¨¡å‹æ€»å‚æ•°é‡: 41,432,027 (41.43M)                   â”‚
   â”‚  é¢„è®­ç»ƒè¦†ç›–ç‡: 94.84%                                 â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 10. ä¾èµ–é¡¹

```bash
torch>=1.10.0
timm>=0.6.0
numpy>=1.21.0
scipy>=1.7.0
h5py>=3.1.0
```



---

## 11.é¡¹ç›®ç»“æ„

SMAFormerV2 ç›¸å…³çš„æ–‡ä»¶ç»„ç»‡ï¼š

```
AFFSegNnet_VMUnetVis/
â”‚
â”œâ”€â”€ models/                                    # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ SMAFormerV2.py                        # âœ¨ SMAFormerV2 ä¸»æ¨¡å‹
â”‚   â”œâ”€â”€ SMAFormerV2_README.md                 # æœ¬æ–‡æ¡£
â”‚   â”œâ”€â”€ SMAFormerV2_arch.html                 # âœ¨ æ¶æ„å¯è§†åŒ– HTML
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ configs/                                   # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ config_setting_synapse.py             # âœ¨ Synapse æ•°æ®é›†é…ç½®
â”‚   â”‚   â””â”€â”€ smaformerv2_config {...}          #    SMAFormerV2 é…ç½®æ®µ
â”‚   â”œâ”€â”€ config_setting_lits2017.py            # LiTS2017 é…ç½®
â”‚   â””â”€â”€ config_setting_ACDC.py                # ACDC é…ç½®
â”‚
â”œâ”€â”€ train_synapse.py                          # âœ¨ è®­ç»ƒè„šæœ¬
â”œâ”€â”€ test_synapse.py                           # âœ¨ æµ‹è¯•è„šæœ¬
â”œâ”€â”€ engine_synapse.py                         # è®­ç»ƒ/éªŒè¯å¼•æ“
â”‚
â”œâ”€â”€ datasets/                                  # æ•°æ®é›†åŠ è½½
â”‚   â”œâ”€â”€ dataset.py                            # Synapse æ•°æ®é›†
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ utils.py                                   # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ cal_params_flops()                    # å‚æ•°é‡/FLOPs è®¡ç®—
â”‚   â”œâ”€â”€ test_single_volume()                  # 3D ä½“ç§¯æµ‹è¯•
â”‚   â””â”€â”€ calculate_metric_percase()            # Dice/HD95 è®¡ç®—
â”‚
â”œâ”€â”€ data/                                      # æ•°æ®ç›®å½•
â”‚   â””â”€â”€ Synapse/                              # âœ¨ Synapse æ•°æ®é›†
â”‚       â”œâ”€â”€ train_npz/                        #    è®­ç»ƒæ•°æ® (NPZ)
â”‚       â”‚   â”œâ”€â”€ case0001_slice000.npz
â”‚       â”‚   â”œâ”€â”€ case0001_slice001.npz
â”‚       â”‚   â””â”€â”€ ...
â”‚       â”œâ”€â”€ test_vol_h5/                      #    æµ‹è¯•æ•°æ® (H5)
â”‚       â”‚   â”œâ”€â”€ case0001.npy.h5
â”‚       â”‚   â””â”€â”€ ...
â”‚       â””â”€â”€ lists/lists_Synapse/              #    æ•°æ®åˆ—è¡¨
â”‚           â”œâ”€â”€ train.txt                     #    è®­ç»ƒé›†åˆ—è¡¨
â”‚           â”œâ”€â”€ test_vol.txt                  #    æµ‹è¯•ä½“ç§¯åˆ—è¡¨
â”‚           â””â”€â”€ test_slice.txt                #    æµ‹è¯•åˆ‡ç‰‡åˆ—è¡¨
â”‚
â”œâ”€â”€ pre_trained_weights/                       # é¢„è®­ç»ƒæƒé‡
â”‚   â””â”€â”€ swin_tiny_patch4_window7_224.pth      # âœ¨ Swin-Tiny é¢„è®­ç»ƒ
â”‚
â”œâ”€â”€ results/                                   # è®­ç»ƒç»“æœ
â”‚   â””â”€â”€ SMAFormerV2_Synapse/                  # âœ¨ SMAFormerV2 å®éªŒ
â”‚       â”œâ”€â”€ checkpoints/                      #    æ¨¡å‹æƒé‡
â”‚       â”‚   â”œâ”€â”€ best.pth                      #    æœ€ä½³æ¨¡å‹
â”‚       â”‚   â”œâ”€â”€ best_dice.pth                 #    æœ€ä½³ Dice
â”‚       â”‚   â””â”€â”€ latest.pth                    #    æœ€æ–°æ£€æŸ¥ç‚¹
â”‚       â”œâ”€â”€ train_record.csv                  #    è®­ç»ƒè®°å½•
â”‚       â”œâ”€â”€ val_record.csv                    #    éªŒè¯è®°å½•
â”‚       â”œâ”€â”€ log/                              #    è®­ç»ƒæ—¥å¿—
â”‚       â””â”€â”€ outputs/                          #    é¢„æµ‹å¯è§†åŒ–
â”‚
â”œâ”€â”€ test_result/                               # æµ‹è¯•ç»“æœ
â”‚   â””â”€â”€ SMAFormerV2_Synapse/
â”‚       â”œâ”€â”€ test_results_detailed.json        # è¯¦ç»†ç»“æœ
â”‚       â”œâ”€â”€ test_results_summary.csv          # ç»“æœæ±‡æ€»
â”‚       â””â”€â”€ visualizations/                   # å¯è§†åŒ–
â”‚
â””â”€â”€ SMAFORMERV2_README.md                     # V2 æ€»ä½“æ–‡æ¡£
```

### å…³é”®æ–‡ä»¶è¯´æ˜

| æ–‡ä»¶/ç›®å½• | ç”¨é€” | é‡è¦æ€§ |
|----------|------|--------|
| `models/SMAFormerV2.py` | æ¨¡å‹å®šä¹‰ï¼šSMAã€E-MLPã€DecoderStageã€EdgeEnhancement | â­â­â­ |
| `models/SMAFormerV2_arch.html` | äº¤äº’å¼æ¶æ„å¯è§†åŒ–ï¼ŒåŒ…å«æµç¨‹å›¾ã€æ¨¡å—å›¾ | â­â­â­ |
| `configs/config_setting_synapse.py` | æ¨¡å‹é…ç½®ã€è®­ç»ƒè¶…å‚æ•°ã€æ•°æ®è·¯å¾„ | â­â­â­ |
| `train_synapse.py` | è®­ç»ƒä¸»å¾ªç¯ã€æ¨¡å‹åˆ›å»ºã€ä¼˜åŒ–å™¨è®¾ç½® | â­â­â­ |
| `test_synapse.py` | æµ‹è¯•è„šæœ¬ã€æŒ‡æ ‡è®¡ç®—ã€ç»“æœä¿å­˜ | â­â­â­ |
| `pre_trained_weights/swin_tiny_*.pth` | Swin Transformer é¢„è®­ç»ƒæƒé‡ | â­â­â­ |
| `results/SMAFormerV2_Synapse/checkpoints/` | è®­ç»ƒäº§ç”Ÿçš„æ¨¡å‹æƒé‡ | â­â­â­ |

---


## 2. Prepare the pre_trained weights and Data

æ•°æ®éµå®ˆSwinUnetçš„åˆ’åˆ†æ ¼å¼ï¼Œå°† Synapse æ•°æ®é›†ç»„ç»‡ä¸ºä»¥ä¸‹ç»“æ„ï¼š

```
data/Synapse/
â”œâ”€â”€ train_npz/          # è®­ç»ƒæ•°æ® (2D åˆ‡ç‰‡)
â”‚   â”œâ”€â”€ case0001_slice000.npz
â”‚   â””â”€â”€ ...
â”œâ”€â”€ test_vol_h5/        # æµ‹è¯•æ•°æ® (3D ä½“ç§¯)
â”‚   â”œâ”€â”€ case0001.npy.h5
â”‚   â””â”€â”€ ...
â””â”€â”€ lists/lists_Synapse/
    â”œâ”€â”€ train.txt       # è®­ç»ƒé›†æ–‡ä»¶å
    â””â”€â”€ test_vol.txt    # æµ‹è¯•é›†æ–‡ä»¶å
```
- The weights of the pre-trained SMAFormer could be downloaded from [Swin Transformer](https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth).





---

## 12. è®­ç»ƒæŠ€å·§

### 1. å­¦ä¹ ç‡è°ƒåº¦

ä½¿ç”¨ CosineAnnealingLRï¼š

```python
# åˆå§‹å­¦ä¹ ç‡
initial_lr = 3e-4

# Cosine é€€ç«
lr_t = lr_min + 0.5 * (initial_lr - lr_min) * (1 + cos(Ï€ * t / T))
```

### 2. æ•°æ®å¢å¼º

```python
transform_train = transforms.Compose([
    RandomGenerator(output_size=[256, 256])  # éšæœºè£å‰ªã€æ—‹è½¬ã€ç¿»è½¬
])
```

### 3. æŸå¤±å‡½æ•°

æ··åˆæŸå¤±ï¼š

```python
loss = ce_loss + dice_loss

# CE Loss: é€åƒç´ äº¤å‰ç†µ
ce = CrossEntropyLoss()(pred, target)

# Dice Loss: ä¼˜åŒ– Dice ç³»æ•°
dice = DiceLoss()(pred, target)
```

### 4. æ¢¯åº¦è£å‰ª

é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼š

```python
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

---

## 13. å¯è§†åŒ–

æ‰“å¼€ `models/SMAFormerV2_arch.html` æŸ¥çœ‹äº¤äº’å¼æ¶æ„å¯è§†åŒ–ï¼ŒåŒ…æ‹¬ï¼š

- ğŸ—ï¸ å®Œæ•´çš„ç½‘ç»œæ¶æ„å›¾
- ğŸ“Š å‚æ•°é‡å’Œ FLOPs ç»Ÿè®¡
- ğŸ”§ SMA æ¨¡å—è¯¦è§£
- âš¡ E-MLP ç»“æ„è¯´æ˜
- ğŸ“ å®Œæ•´çš„è°ƒç”¨å…³ç³»å›¾ï¼ˆCall Graphï¼‰
- ğŸ”„ æ•°æ®æµå‘å›¾ï¼ˆFlow Chartï¼‰
- ğŸ“‹ æƒé‡åŠ è½½è¯¦æƒ…è¡¨

---

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•åˆ‡æ¢æ•°æ®é›†ï¼Ÿ

ä¿®æ”¹ `configs/config_setting_synapse.py`ï¼š

```python
datasets_name = 'Synapse'  # æˆ– 'LiTS2017', 'ACDC'
```

æ¨¡å‹ä¼šè‡ªåŠ¨æ ¹æ®æ•°æ®é›†è°ƒæ•´ç±»åˆ«æ•°ã€‚

### Q2: å¦‚ä½•è°ƒæ•´æ¨¡å‹å¤§å°ï¼Ÿ

ç›®å‰ä½¿ç”¨ Swin-Tinyï¼Œå¯ä»¥é€šè¿‡ä¿®æ”¹ `SMAFormerV2.py` ä¸­çš„ `embed_dims` å‚æ•°æ¥è°ƒæ•´ï¼š

```python
# Swin-Tiny (é»˜è®¤)
embed_dims = [96, 192, 384, 768]

# æ›´å°çš„æ¨¡å‹
embed_dims = [64, 128, 256, 512]

# æ›´å¤§çš„æ¨¡å‹ (Swin-Small)
embed_dims = [96, 192, 384, 768]
depths = [2, 2, 18, 2]  # å¢åŠ  depth
```

### Q3: è®­ç»ƒæ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

å‡å° batch sizeï¼š

```python
# configs/config_setting_synapse.py
batch_size = 16  # ä» 28 å‡å°‘åˆ° 16
```

æˆ–ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼š

```python
accumulation_steps = 2
loss = loss / accumulation_steps
loss.backward()
if (i + 1) % accumulation_steps == 0:
    optimizer.step()
    optimizer.zero_grad()
```

### Q4: å¦‚ä½•åªä½¿ç”¨éƒ¨åˆ†æ”¹è¿›ï¼Ÿ

ä¿®æ”¹é…ç½®ï¼ˆè™½ç„¶å½“å‰ç‰ˆæœ¬éƒ½æ˜¯é»˜è®¤å¼€å¯çš„ï¼‰ï¼š

```python
# å…³é—­è¾¹ç¼˜å¢å¼º
model = SMAFormerV2(
    ...,
    use_edge_enhancement=False
)
```

### Q5: å¯ä»¥åŠ è½½ HBFormer çš„æƒé‡å—ï¼Ÿ

å¯ä»¥éƒ¨åˆ†åŠ è½½ç¼–ç å™¨æƒé‡ï¼Œå› ä¸ºéƒ½ä½¿ç”¨ Swin Transformerï¼š

```python
# åŠ è½½ HBFormer checkpoint
checkpoint = torch.load('hbformer_checkpoint.pth')

# æå– encoder æƒé‡
encoder_weights = {k: v for k, v in checkpoint.items() 
                   if k.startswith('encoder.')}

# åŠ è½½åˆ° SMAFormerV2
model.encoder.load_state_dict(encoder_weights, strict=False)
```

### ä¸ºä»€ä¹ˆé€‰æ‹©é•œåƒæ¶æ„ï¼Ÿ

ä¼ ç»Ÿçš„åŒ»å­¦å›¾åƒåˆ†å‰²æ¨¡å‹ï¼ˆå¦‚UNetã€TransUNetï¼‰é€šå¸¸åªåœ¨Encoderéƒ¨åˆ†ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼ŒDecoderéƒ¨åˆ†ä»éšæœºåˆå§‹åŒ–å¼€å§‹è®­ç»ƒã€‚è¿™å¯¼è‡´ï¼š
1. é¢„è®­ç»ƒæƒé‡åˆ©ç”¨ç‡ä½ï¼ˆé€šå¸¸<60%ï¼‰
2. Decoderéœ€è¦ä»å¤´å­¦ä¹ ï¼Œæ”¶æ•›æ…¢
3. å®¹æ˜“è¿‡æ‹Ÿåˆï¼ˆDecoderéšæœºåˆå§‹åŒ–ï¼‰

V2.3é€šè¿‡**è®©Decoderé•œåƒEncoderç»“æ„**ï¼Œå®ç°äº†ï¼š
1. Decoderä¹Ÿå¯ä»¥åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆåå‘æ˜ å°„ï¼‰
2. é¢„è®­ç»ƒè¦†ç›–ç‡æå‡è‡³94.84%
3. è®­ç»ƒæ›´ç¨³å®šï¼Œæ”¶æ•›æ›´å¿«
4. é¿å…è¿‡åº¦è®¾è®¡å¤æ‚æ¨¡å—

### ä¸ºä»€ä¹ˆDecoderåŠ è½½ç‡æ˜¯85.87%è€Œé100%ï¼Ÿ

Decoderæ— æ³•100%åŠ è½½çš„åŸå› ï¼š
1. **PatchExpandingæ¨¡å—**æ˜¯æ–°è®¾è®¡çš„ï¼ˆPatchMergingçš„é€†æ“ä½œï¼‰ï¼Œæ²¡æœ‰å¯¹åº”çš„é¢„è®­ç»ƒæƒé‡
2. **Skip connectionçš„projectionå±‚**éœ€è¦å¤„ç†concatenationåçš„ç‰¹å¾ï¼Œä¸é¢„è®­ç»ƒä¸åŒ¹é…
3. **è¾“å…¥ç»´åº¦ä¸åŒ**ï¼šDecoderå„stageçš„è¾“å…¥ç»´åº¦ä¸Encoderä¸å®Œå…¨å¯¹ç§°

ä½†å³ä¾¿å¦‚æ­¤ï¼Œ85.87%çš„DecoderåŠ è½½ç‡å·²ç»è¿œè¶…ä¼ ç»Ÿæ¶æ„çš„0%ã€‚


---

# ğŸ§§ Acknowledgement

This work was supported in part by the National Key R\&D Project of China (2018YFA0704102, 2018YFA0704104), in part by Natural Science Foundation of Guangdong Province (No. 2023A1515010673), and in part by Shenzhen Technology Innovation Commission (No. JSGG20220831110400001), in part by Shenzhen Development and Reform Commission (No. XMHT20220104009), in part by the Science and Technology Development Fund, Macau SAR, under Grant 0141/2023/RIA2 and 0193/2023/RIA3.


