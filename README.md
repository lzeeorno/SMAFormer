# ðŸ›Ž Citation

If you find our work helpful for your research, please cite:

```bib
@inproceedings{zheng2024smaformer,
  title={Smaformer: Synergistic multi-attention transformer for medical image segmentation},
  author={Zheng, Fuchen and Chen, Xuhang and Liu, Weihuang and Li, Haolun and Lei, Yingtie and He, Jiahui and Pun, Chi-Man and Zhou, Shoujun},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
  pages={4048--4053},
  year={2024},
  organization={IEEE}
}

```
# ðŸ“‹SMAFormer

SMAFormer: Synergistic Multi-Attention Transformer for Medical Image Segmentation
[Vedio introduction](https://www.bilibili.com/video/BV1FLDsYqExZ/)

[Fuchen Zheng](https://lzeeorno.github.io/),  [Xuhang Chen](https://cxh.netlify.app/), Weihuang Liu, Haolun Li, Yingtie Lei, Jiahui He, [Chi-Man Pun](https://www.cis.um.edu.mo/~cmpun/) ðŸ“®and [Shoujun Zhou](https://people.ucas.edu.cn/~sjzhou?language=en) ðŸ“®( ðŸ“® Corresponding authors)

**University of Macau, SIAT CAS, Huizhou University, University of Nottingham Ningbo China**

2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM 2024)

## ðŸš§ Installation 
Requirements: `Ubuntu 20.04`

1. Create a virtual environment: `conda create -n your_environment python=3.8 -y` and `conda activate your_environment `
2. Install [Pytorch](https://pytorch.org/get-started/previous-versions/#linux-and-windows-4) :`pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu118`
Or you can use Tsinghua Source for installation
```bash
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
pip install torch==2.0.0+cu118 torchvision==0.15.1+cu118 torchaudio==2.0.1+cu118 -f https://download.pytorch.org/whl/torch_stable.html
```
3. `pip install tqdm scikit-learn albumentations==1.0.3 pandas einops axial_attention`
4. `pip install xlsxwriter`


## 1. æ¦‚è¿°

SMAFormer æ˜¯ä¸€ä¸ªä¸“ä¸ºåŒ»å­¦å›¾åƒåˆ†å‰²è®¾è®¡çš„æ·±åº¦å­¦ä¹ æž¶æž„ï¼Œç»“åˆäº† Swin Transformer çš„åˆ†å±‚ç‰¹å¾æå–èƒ½åŠ›å’Œ Synergistic Multi-Attention (SMA) æœºåˆ¶çš„ç»†èŠ‚æ„ŸçŸ¥èƒ½åŠ›ã€‚è¯¥æ¨¡åž‹åœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½Žäº†å‚æ•°é‡å’Œè®¡ç®—å¤æ‚åº¦ï¼Œç‰¹åˆ«é€‚åˆå¤šå™¨å®˜åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ã€‚

### æ ¸å¿ƒç‰¹ç‚¹

- ðŸ—ï¸ **åˆ†å±‚æž¶æž„**: åŸºäºŽ Swin Transformer çš„å››é˜¶æ®µç¼–ç å™¨ï¼Œæä¾›å¤šå°ºåº¦ç‰¹å¾é‡‘å­—å¡”
- ðŸŽ¯ **SMA å¢žå¼º**: ååŒèžåˆåƒç´ ã€é€šé“å’Œç©ºé—´ä¸‰ç§æ³¨æ„åŠ›æœºåˆ¶
- âš¡ **é«˜æ•ˆè®¾è®¡**: 42.66M å‚æ•°ï¼Œ30.50 GFLOPsï¼Œè®­ç»ƒå’ŒæŽ¨ç†é€Ÿåº¦å¿«
- ðŸ”§ **é¢„è®­ç»ƒåŠ è½½**: 94.35% çš„ç¼–ç å™¨å‚æ•°åŠ è½½ ImageNet é¢„è®­ç»ƒæƒé‡
- ðŸŽ¨ **è¾¹ç¼˜å¢žå¼º**: å†…ç½® Sobel è¾¹ç¼˜æ£€æµ‹æå‡åˆ†å‰²è¾¹ç•Œç²¾åº¦

---

## æž¶æž„è®¾è®¡

### æ•´ä½“æµç¨‹

```
è¾“å…¥å›¾åƒ (3 Ã— 256 Ã— 256)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Input Projection Layer                                     â”‚
â”‚  3Ã—3 Conv + ReLU                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Swin Transformer Encoder (é¢„è®­ç»ƒ: 94.35%)                  â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  SMA  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  SMA  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  SMA   â”‚
â”‚  â”‚ Stage 1  â”‚  â”€â”€â”€â†’ â”‚ Stage 2  â”‚  â”€â”€â”€â†’ â”‚ Stage 3  â”‚  â”€â”€â”€â†’  â”‚
â”‚  â”‚ 96Ã—64Ã—64 â”‚   1   â”‚192Ã—32Ã—32 â”‚   2   â”‚384Ã—16Ã—16 â”‚   3   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â”‚
â”‚       â”‚                  â”‚                  â”‚              â”‚
â”‚       F1                 F2                 F3             â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  SMA                                          â”‚
â”‚  â”‚ Stage 4  â”‚  â”€â”€â”€â†’ (Bottleneck)                           â”‚
â”‚  â”‚768Ã—8Ã—8   â”‚   4                                           â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚       â”‚                                                      â”‚
â”‚       F4                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Symmetric Decoder (éšæœºåˆå§‹åŒ–)                              â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Decoder 4   â”‚ â†â”€  â”‚  Decoder 3   â”‚ â†â”€  â”‚  Decoder 2   â”‚â”‚
â”‚  â”‚  768â†’384     â”‚ F3  â”‚  384â†’192     â”‚ F2  â”‚  192â†’96      â”‚â”‚
â”‚  â”‚+ 2Ã—SMA Block â”‚     â”‚+ 2Ã—SMA Block â”‚     â”‚+ 2Ã—SMA Block â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚         â”‚ UpsampleÃ—2         â”‚ UpsampleÃ—2         â”‚        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                             â†“                                â”‚
â”‚                    96 Ã— 64 Ã— 64                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Final Upsampling + Edge Enhancement                        â”‚
â”‚  ConvTranspose2d (Ã—4) + Sobel Edge Detection                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
è¾“å‡ºåˆ†å‰²å›¾ (num_classes Ã— 256 Ã— 256)
```

### ç¼–ç å™¨ - Swin Transformer Backbone

é‡‡ç”¨ Swin Transformer Tiny ä½œä¸ºç‰¹å¾æå–å™¨ï¼š

| Stage | Input Size | Depth | Heads | Channels | Output Size | é¢„è®­ç»ƒ |
|-------|-----------|-------|-------|----------|-------------|--------|
| Patch Embed | 256Ã—256Ã—3 | - | - | - | 96Ã—64Ã—64 | âœ… |
| Stage 1 | 96Ã—64Ã—64 | 2 | 3 | 96 | 96Ã—64Ã—64 | âœ… |
| Stage 2 | 96Ã—64Ã—64 | 2 | 6 | 192 | 192Ã—32Ã—32 | âœ… |
| Stage 3 | 192Ã—32Ã—32 | 6 | 12 | 384 | 384Ã—16Ã—16 | âœ… |
| Stage 4 | 384Ã—16Ã—16 | 2 | 24 | 768 | 768Ã—8Ã—8 | âœ… |

**å…³é”®ç‰¹æ€§**ï¼š
- **çª—å£æ³¨æ„åŠ›**: 7Ã—7 çª—å£å¤§å°ï¼Œè®¡ç®—å¤æ‚åº¦ O(n) è€Œéž O(nÂ²)
- **Shifted Window**: äº¤æ›¿ä½¿ç”¨å¸¸è§„çª—å£å’Œåç§»çª—å£ï¼Œå®žçŽ°è·¨çª—å£ä¿¡æ¯äº¤äº’
- **å±‚æ¬¡ç‰¹å¾**: å››ä¸ªä¸åŒåˆ†è¾¨çŽ‡çš„ç‰¹å¾å±‚ï¼Œè‡ªç„¶é€‚é… U-Net é£Žæ ¼è§£ç å™¨

---

## é¡¹ç›®ç»“æž„

SMAFormerV2 ç›¸å…³çš„æ–‡ä»¶ç»„ç»‡ï¼š

```
AFFSegNnet_VMUnetVis/
â”‚
â”œâ”€â”€ models/                                    # æ¨¡åž‹å®šä¹‰
â”‚   â”œâ”€â”€ SMAFormerV2.py                        # âœ¨ SMAFormerV2 ä¸»æ¨¡åž‹
â”‚   â”œâ”€â”€ SMAFormerV2_README.md                 # æœ¬æ–‡æ¡£
â”‚   â”œâ”€â”€ SMAFormerV2_arch.html                 # âœ¨ æž¶æž„å¯è§†åŒ– HTML
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ configs/                                   # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ config_setting_synapse.py             # âœ¨ Synapse æ•°æ®é›†é…ç½®
â”‚   â”‚   â””â”€â”€ smaformerv2_config {...}          #    SMAFormerV2 é…ç½®æ®µ
â”‚   â”œâ”€â”€ config_setting_lits2017.py            # LiTS2017 é…ç½®
â”‚   â””â”€â”€ config_setting_ACDC.py                # ACDC é…ç½®
â”‚
â”œâ”€â”€ train_synapse.py                          # âœ¨ è®­ç»ƒè„šæœ¬
â”œâ”€â”€ test_synapse.py                           # âœ¨ æµ‹è¯•è„šæœ¬
â”œâ”€â”€ engine_synapse.py                         # è®­ç»ƒ/éªŒè¯å¼•æ“Ž
â”‚
â”œâ”€â”€ datasets/                                  # æ•°æ®é›†åŠ è½½
â”‚   â”œâ”€â”€ dataset.py                            # Synapse æ•°æ®é›†
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ utils.py                                   # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ cal_params_flops()                    # å‚æ•°é‡/FLOPs è®¡ç®—
â”‚   â”œâ”€â”€ test_single_volume()                  # 3D ä½“ç§¯æµ‹è¯•
â”‚   â””â”€â”€ calculate_metric_percase()            # Dice/HD95 è®¡ç®—
â”‚
â”œâ”€â”€ data/                                      # æ•°æ®ç›®å½•
â”‚   â””â”€â”€ Synapse/                              # âœ¨ Synapse æ•°æ®é›†
â”‚       â”œâ”€â”€ train_npz/                        #    è®­ç»ƒæ•°æ® (NPZ)
â”‚       â”‚   â”œâ”€â”€ case0001_slice000.npz
â”‚       â”‚   â”œâ”€â”€ case0001_slice001.npz
â”‚       â”‚   â””â”€â”€ ...
â”‚       â”œâ”€â”€ test_vol_h5/                      #    æµ‹è¯•æ•°æ® (H5)
â”‚       â”‚   â”œâ”€â”€ case0001.npy.h5
â”‚       â”‚   â””â”€â”€ ...
â”‚       â””â”€â”€ lists/lists_Synapse/              #    æ•°æ®åˆ—è¡¨
â”‚           â”œâ”€â”€ train.txt                     #    è®­ç»ƒé›†åˆ—è¡¨
â”‚           â”œâ”€â”€ test_vol.txt                  #    æµ‹è¯•ä½“ç§¯åˆ—è¡¨
â”‚           â””â”€â”€ test_slice.txt                #    æµ‹è¯•åˆ‡ç‰‡åˆ—è¡¨
â”‚
â”œâ”€â”€ pre_trained_weights/                       # é¢„è®­ç»ƒæƒé‡
â”‚   â””â”€â”€ swin_tiny_patch4_window7_224.pth      # âœ¨ Swin-Tiny é¢„è®­ç»ƒ
â”‚
â”œâ”€â”€ results/                                   # è®­ç»ƒç»“æžœ
â”‚   â””â”€â”€ SMAFormerV2_Synapse/                  # âœ¨ SMAFormerV2 å®žéªŒ
â”‚       â”œâ”€â”€ checkpoints/                      #    æ¨¡åž‹æƒé‡
â”‚       â”‚   â”œâ”€â”€ best.pth                      #    æœ€ä½³æ¨¡åž‹
â”‚       â”‚   â”œâ”€â”€ best_dice.pth                 #    æœ€ä½³ Dice
â”‚       â”‚   â””â”€â”€ latest.pth                    #    æœ€æ–°æ£€æŸ¥ç‚¹
â”‚       â”œâ”€â”€ train_record.csv                  #    è®­ç»ƒè®°å½•
â”‚       â”œâ”€â”€ val_record.csv                    #    éªŒè¯è®°å½•
â”‚       â”œâ”€â”€ log/                              #    è®­ç»ƒæ—¥å¿—
â”‚       â””â”€â”€ outputs/                          #    é¢„æµ‹å¯è§†åŒ–
â”‚
â”œâ”€â”€ test_result/                               # æµ‹è¯•ç»“æžœ
â”‚   â””â”€â”€ SMAFormerV2_Synapse/
â”‚       â”œâ”€â”€ test_results_detailed.json        # è¯¦ç»†ç»“æžœ
â”‚       â”œâ”€â”€ test_results_summary.csv          # ç»“æžœæ±‡æ€»
â”‚       â””â”€â”€ visualizations/                   # å¯è§†åŒ–
â”‚
â””â”€â”€ SMAFORMERV2_README.md                     # V2 æ€»ä½“æ–‡æ¡£
```

### å…³é”®æ–‡ä»¶è¯´æ˜Ž

| æ–‡ä»¶/ç›®å½• | ç”¨é€” | é‡è¦æ€§ |
|----------|------|--------|
| `models/SMAFormerV2.py` | æ¨¡åž‹å®šä¹‰ï¼šSMAã€E-MLPã€DecoderStageã€EdgeEnhancement | â­â­â­ |
| `models/SMAFormerV2_arch.html` | äº¤äº’å¼æž¶æž„å¯è§†åŒ–ï¼ŒåŒ…å«æµç¨‹å›¾ã€æ¨¡å—å›¾ | â­â­â­ |
| `configs/config_setting_synapse.py` | æ¨¡åž‹é…ç½®ã€è®­ç»ƒè¶…å‚æ•°ã€æ•°æ®è·¯å¾„ | â­â­â­ |
| `train_synapse.py` | è®­ç»ƒä¸»å¾ªçŽ¯ã€æ¨¡åž‹åˆ›å»ºã€ä¼˜åŒ–å™¨è®¾ç½® | â­â­â­ |
| `test_synapse.py` | æµ‹è¯•è„šæœ¬ã€æŒ‡æ ‡è®¡ç®—ã€ç»“æžœä¿å­˜ | â­â­â­ |
| `pre_trained_weights/swin_tiny_*.pth` | Swin Transformer é¢„è®­ç»ƒæƒé‡ | â­â­â­ |
| `results/SMAFormerV2_Synapse/checkpoints/` | è®­ç»ƒäº§ç”Ÿçš„æ¨¡åž‹æƒé‡ | â­â­â­ |

---


## 2. Prepare the pre_trained weights and Data

æ•°æ®éµå®ˆSwinUnetçš„åˆ’åˆ†æ ¼å¼ï¼Œå°† Synapse æ•°æ®é›†ç»„ç»‡ä¸ºä»¥ä¸‹ç»“æž„ï¼š

```
data/Synapse/
â”œâ”€â”€ train_npz/          # è®­ç»ƒæ•°æ® (2D åˆ‡ç‰‡)
â”‚   â”œâ”€â”€ case0001_slice000.npz
â”‚   â””â”€â”€ ...
â”œâ”€â”€ test_vol_h5/        # æµ‹è¯•æ•°æ® (3D ä½“ç§¯)
â”‚   â”œâ”€â”€ case0001.npy.h5
â”‚   â””â”€â”€ ...
â””â”€â”€ lists/lists_Synapse/
    â”œâ”€â”€ train.txt       # è®­ç»ƒé›†æ–‡ä»¶å
    â””â”€â”€ test_vol.txt    # æµ‹è¯•é›†æ–‡ä»¶å
```
- The weights of the pre-trained SMAFormer could be downloaded from [Swin Transformer](https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth).


### 3. é…ç½®æ¨¡åž‹

ç¼–è¾‘ `configs/config_setting_synapse.py`ï¼š

```python
# é€‰æ‹© SMAFormerV2
network = 'SMAFormerV2'

# SMAFormerV2 é…ç½®
smaformerv2_config = {
    'num_classes': 9,                          # Synapse: 9 ç±»
    'input_channels': 3,                       # RGB è¾“å…¥
    'img_size': (256, 256),                    # è¾“å…¥å°ºå¯¸
    'swin_pretrained_path': 'pre_trained_weights/swin_tiny_patch4_window7_224.pth',
    'use_edge_enhancement': True,              # å¯ç”¨è¾¹ç¼˜å¢žå¼º
}
```

### 4. è®­ç»ƒæ¨¡åž‹

```bash
# æ¿€æ´»çŽ¯å¢ƒ
conda activate seg

# å¼€å§‹è®­ç»ƒ
python train_synapse.py

# æŒ‡å®š GPU
CUDA_VISIBLE_DEVICES=0 python train_synapse.py
```

**è®­ç»ƒå‚æ•°**ï¼ˆåœ¨ config ä¸­é…ç½®ï¼‰ï¼š
- Batch Size: 28
- Learning Rate: 3e-4
- Optimizer: AdamW
- Scheduler: CosineAnnealingLR
- Epochs: 150
- Loss: CrossEntropy + Dice

### 5. æµ‹è¯•æ¨¡åž‹

```bash
# æµ‹è¯•ï¼ˆè‡ªåŠ¨åŠ è½½ best.pthï¼‰
python test_synapse.py

# æµ‹è¯•å¹¶ä¿å­˜å¯è§†åŒ–
python test_synapse.py --save_vis
```

### 6. ä»£ç è°ƒç”¨

```python
from models.SMAFormerV2 import SMAFormerV2
import torch

# åˆ›å»º args å¯¹è±¡
class Args:
    def __init__(self):
        self.dataset = 'Synapse'

args = Args()

# åˆ›å»ºæ¨¡åž‹
model = SMAFormerV2(
    args=args,
    img_size=256,                              # è¾“å…¥å°ºå¯¸
    num_classes=9,                             # ç±»åˆ«æ•°
    pretrained_path='pre_trained_weights/swin_tiny_patch4_window7_224.pth',
    use_edge_enhancement=True                  # è¾¹ç¼˜å¢žå¼º
).cuda()

# å‰å‘ä¼ æ’­
x = torch.randn(2, 3, 256, 256).cuda()
with torch.no_grad():
    output = model(x)  # [2, 9, 256, 256]

print(f"Input: {x.shape}, Output: {output.shape}")
```

---

## æ¨¡åž‹æ€§èƒ½

### å‚æ•°é‡ä¸Žè®¡ç®—é‡

| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜Ž |
|------|------|------|
| **æ€»å‚æ•°é‡** | 42.66M | æ¯”åŽŸç‰ˆ SMAFormer å‡å°‘ 69% |
| **GFLOPs** | 30.50 | æ¯”åŽŸç‰ˆ SMAFormer å‡å°‘ 76% |
| **Encoder å‚æ•°** | 27.52M (64.5%) | 94.35% åŠ è½½é¢„è®­ç»ƒ |
| **SMA å‚æ•°** | 2.46M (5.8%) | éšæœºåˆå§‹åŒ– |
| **Decoder å‚æ•°** | 12.52M (29.3%) | éšæœºåˆå§‹åŒ– |

### é¢„è®­ç»ƒæƒé‡åŠ è½½

è¿è¡Œæ—¶è¾“å‡ºçš„æƒé‡åŠ è½½æŠ¥å‘Šï¼š

```
======================================================================
SMAFormerV2 é¢„è®­ç»ƒæƒé‡åŠ è½½æŠ¥å‘Š
======================================================================

ðŸ“¦ é¢„è®­ç»ƒæƒé‡æ–‡ä»¶: pre_trained_weights/swin_tiny_patch4_window7_224.pth
   é¢„è®­ç»ƒæƒé‡æ€»å±‚æ•°: 190
   æ¨¡åž‹Encoderæ€»å±‚æ•°: 171

ðŸ“Š æƒé‡åŠ è½½ç»Ÿè®¡:
   â”œâ”€ æˆåŠŸåŒ¹é…çš„å±‚æ•°: 162 / 171
   â”œâ”€ æˆåŠŸåŠ è½½çš„å‚æ•°é‡: 25,965,690
   â”œâ”€ Encoderæ€»å‚æ•°é‡: 27,519,354
   â””â”€ Encoderé¢„è®­ç»ƒæƒé‡è¦†ç›–çŽ‡: 94.35%

ðŸ“ˆ æ¨¡åž‹å„éƒ¨åˆ†å‚æ•°ç»Ÿè®¡:
   â”œâ”€ Encoder (Swin): 27,519,354 (27.52M)
   â”œâ”€ SMA Stages: 2,455,976 (2.46M)
   â”œâ”€ Decoder: 12,518,028 (12.52M)
   â””â”€ æ€»å‚æ•°é‡: 42,661,643 (42.66M)

âœ… Encoderæƒé‡åŠ è½½å®Œæˆ!
   - é¢„è®­ç»ƒæƒé‡åˆ©ç”¨çŽ‡: 90.99%
   - Decoderæƒé‡: éšæœºåˆå§‹åŒ– (éœ€è¦è®­ç»ƒ)
======================================================================
```

### è®­ç»ƒæ€§èƒ½

åŸºäºŽ RTX 4090 çš„è®­ç»ƒé€Ÿåº¦ï¼š

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| è®­ç»ƒé€Ÿåº¦ | ~5.8 it/s (batch_size=28) |
| å• epoch æ—¶é—´ | ~125 ç§’ |
| éªŒè¯é€Ÿåº¦ (slice) | ~72 slices/s |
| GPU æ˜¾å­˜ | ~8GB (è®­ç»ƒ) / ~2GB (æŽ¨ç†) |


---

## è®­ç»ƒæŠ€å·§

### 1. å­¦ä¹ çŽ‡è°ƒåº¦

ä½¿ç”¨ CosineAnnealingLRï¼š

```python
# åˆå§‹å­¦ä¹ çŽ‡
initial_lr = 3e-4

# Cosine é€€ç«
lr_t = lr_min + 0.5 * (initial_lr - lr_min) * (1 + cos(Ï€ * t / T))
```

### 2. æ•°æ®å¢žå¼º

```python
transform_train = transforms.Compose([
    RandomGenerator(output_size=[256, 256])  # éšæœºè£å‰ªã€æ—‹è½¬ã€ç¿»è½¬
])
```

### 3. æŸå¤±å‡½æ•°

æ··åˆæŸå¤±ï¼š

```python
loss = ce_loss + dice_loss

# CE Loss: é€åƒç´ äº¤å‰ç†µ
ce = CrossEntropyLoss()(pred, target)

# Dice Loss: ä¼˜åŒ– Dice ç³»æ•°
dice = DiceLoss()(pred, target)
```

### 4. æ¢¯åº¦è£å‰ª

é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼š

```python
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

---

## å¯è§†åŒ–

æ‰“å¼€ `models/SMAFormerV2_arch.html` æŸ¥çœ‹äº¤äº’å¼æž¶æž„å¯è§†åŒ–ï¼ŒåŒ…æ‹¬ï¼š

- ðŸ—ï¸ å®Œæ•´çš„ç½‘ç»œæž¶æž„å›¾
- ðŸ“Š å‚æ•°é‡å’Œ FLOPs ç»Ÿè®¡
- ðŸ”§ SMA æ¨¡å—è¯¦è§£
- âš¡ E-MLP ç»“æž„è¯´æ˜Ž
- ðŸ“ž å®Œæ•´çš„è°ƒç”¨å…³ç³»å›¾ï¼ˆCall Graphï¼‰
- ðŸ”„ æ•°æ®æµå‘å›¾ï¼ˆFlow Chartï¼‰
- ðŸ“‹ æƒé‡åŠ è½½è¯¦æƒ…è¡¨

---

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•åˆ‡æ¢æ•°æ®é›†ï¼Ÿ

ä¿®æ”¹ `configs/config_setting_synapse.py`ï¼š

```python
datasets_name = 'Synapse'  # æˆ– 'LiTS2017', 'ACDC'
```

æ¨¡åž‹ä¼šè‡ªåŠ¨æ ¹æ®æ•°æ®é›†è°ƒæ•´ç±»åˆ«æ•°ã€‚

### Q2: å¦‚ä½•è°ƒæ•´æ¨¡åž‹å¤§å°ï¼Ÿ

ç›®å‰ä½¿ç”¨ Swin-Tinyï¼Œå¯ä»¥é€šè¿‡ä¿®æ”¹ `SMAFormerV2.py` ä¸­çš„ `embed_dims` å‚æ•°æ¥è°ƒæ•´ï¼š

```python
# Swin-Tiny (é»˜è®¤)
embed_dims = [96, 192, 384, 768]

# æ›´å°çš„æ¨¡åž‹
embed_dims = [64, 128, 256, 512]

# æ›´å¤§çš„æ¨¡åž‹ (Swin-Small)
embed_dims = [96, 192, 384, 768]
depths = [2, 2, 18, 2]  # å¢žåŠ  depth
```

### Q3: è®­ç»ƒæ˜¾å­˜ä¸è¶³æ€Žä¹ˆåŠžï¼Ÿ

å‡å° batch sizeï¼š

```python
# configs/config_setting_synapse.py
batch_size = 16  # ä»Ž 28 å‡å°‘åˆ° 16
```

æˆ–ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼š

```python
accumulation_steps = 2
loss = loss / accumulation_steps
loss.backward()
if (i + 1) % accumulation_steps == 0:
    optimizer.step()
    optimizer.zero_grad()
```

### Q4: å¦‚ä½•åªä½¿ç”¨éƒ¨åˆ†æ”¹è¿›ï¼Ÿ

ä¿®æ”¹é…ç½®ï¼ˆè™½ç„¶å½“å‰ç‰ˆæœ¬éƒ½æ˜¯é»˜è®¤å¼€å¯çš„ï¼‰ï¼š

```python
# å…³é—­è¾¹ç¼˜å¢žå¼º
model = SMAFormerV2(
    ...,
    use_edge_enhancement=False
)
```

### Q5: å¯ä»¥åŠ è½½ HBFormer çš„æƒé‡å—ï¼Ÿ

å¯ä»¥éƒ¨åˆ†åŠ è½½ç¼–ç å™¨æƒé‡ï¼Œå› ä¸ºéƒ½ä½¿ç”¨ Swin Transformerï¼š

```python
# åŠ è½½ HBFormer checkpoint
checkpoint = torch.load('hbformer_checkpoint.pth')

# æå– encoder æƒé‡
encoder_weights = {k: v for k, v in checkpoint.items() 
                   if k.startswith('encoder.')}

# åŠ è½½åˆ° SMAFormerV2
model.encoder.load_state_dict(encoder_weights, strict=False)
```

---

## ä¾èµ–é¡¹

```txt
torch>=1.10.0
torchvision>=0.11.0
timm>=0.6.0
einops>=0.6.0
numpy>=1.21.0
opencv-python>=4.5.0
scipy>=1.7.0
h5py>=3.6.0
medpy>=0.4.0
SimpleITK>=2.1.0
```

---

# ðŸ§§ Acknowledgement

This work was supported in part by the National Key R\&D Project of China (2018YFA0704102, 2018YFA0704104), in part by Natural Science Foundation of Guangdong Province (No. 2023A1515010673), and in part by Shenzhen Technology Innovation Commission (No. JSGG20220831110400001), in part by Shenzhen Development and Reform Commission (No. XMHT20220104009), in part by the Science and Technology Development Fund, Macau SAR, under Grant 0141/2023/RIA2 and 0193/2023/RIA3.


